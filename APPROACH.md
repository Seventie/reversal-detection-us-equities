# Our Approach: From 8 Struggles to Victory ‚úÖ\n\n## Overview: The Three-Phase Strategy\n\nWe're tackling this competition in three phases:\n1. **Feature Engineering**: Build 1,982 rich technical indicators\n2. **Feature Selection & Validation**: Reduce to 50-200 high-quality, causal features\n3. **Model Training & Optimization**: Train classification models with proper safeguards\n\n---\n\n## Phase 1: Comprehensive Feature Engineering ‚úÖ (Current)\n\n### Why This Approach?\n\nInstead of manually picking indicators (traditional approach), we:\n- Generate **thousands of features** across multiple dimensions\n- Let the ML model discover which combinations predict reversals\n- Test multiple parameter values to find optimal thresholds\n- Create both aggressive and conservative signals\n\n### Feature Categories\n\n#### 1. **Core Momentum Features**\n
```\nFeature Name        | What It Measures\n------------------- | ---------------------------------\nratio               | Price relative change (% change)\nmomentum            | Rate of price change (velocity)\nsm_momentum         | Smoothed momentum (noise reduction)\nsm_ratio            | Smoothed ratio (trend direction)\n```\n\n**Intuition**: Reversals often happen when momentum extremes (very high or very low)\n\n**Example**:\n- High positive momentum ‚Üí Price rising fast\n- Negative momentum ‚Üí Price falling fast\n- When momentum changes sign ‚Üí Potential reversal\n\n---\n\n#### 2. **Threshold Crossing Features** (Multiple {X} values)\n
```\nCross from Above:   Price was above X, now drops to X or below\n                    ‚Üí Potential bearish reversal at resistance\n\nCross from Below:   Price was below X, now rises to X or above\n                    ‚Üí Potential bullish reversal at support\n```\n\n**Why Multiple Thresholds?**\n- Support/resistance isn't always at round numbers\n- Different stocks have different key levels\n- Testing 99.0, 99.5, 100.0, 100.5, 101.0, etc.\n- Model learns which thresholds matter most\n\n**Mathematical Definition**:\n```\nfeatures['cross_from_above_{X}_min'] = \n  (price[t-1] >= X) AND (price[t] < X) AND (X is minimal such that this occurs)\n\nfeatures['cross_from_below_{X}_max'] = \n  (price[t-1] <= X) AND (price[t] > X) AND (X is maximal such that this occurs)\n```\n\n---\n\n#### 3. **Trend-Zone Features**\n
```\nTrending Up & Below {X}:    Price rising, but still below resistance level X\n                            ‚Üí Bullish continuation (not reversal yet)\n                            ‚Üí But price is \"building pressure\"\n\nTrending Down & Above {X}:  Price falling, but still above support level X\n                            ‚Üí Bearish continuation (not reversal yet)\n                            ‚Üí But price is \"breaking down\"\n```\n\n**Why This Matters for Reversals**:\n- Before true reversal, price usually approaches (but doesn't break) a level\n- These features capture \"pre-reversal tension\"\n- Model can learn: \"Price at X, trending up ‚Üí likely reverses soon\"\n\n---\n\n#### 4. **Technical Structure Detection**\n
```\nPeaks & Troughs:    Local highs and local lows\n                    ‚Üí Classic reversal points\n                    ‚Üí Multiple thresholds to catch different scales\n\nZone Features:      Price staying within a range (99.0-99.5, 100.0-100.5, etc)\n                    ‚Üí Support/resistance zones\n                    ‚Üí Consolidation before reversal\n```\n\n**Critical Design Decision**: How much lookahead do we use?\n- **To avoid data leakage**: Only look backward to confirm\n- **Strategy**: \"Peak is confirmed after N bars of decline\"\n- **Tradeoff**: Features become slightly lagging (3-5 bar delay)\n- **Benefit**: Can be used in real-time trading\n\n---\n\n### Feature Expansion Across Parameters\n\n**Why {X}?** Parameters create **parameter families**:\n
```\n{X} can be: 98.5, 99.0, 99.5, 100.0, 100.5, 101.0, 101.5, ...\n
So instead of:\n  cross_threshold_from_above (1 feature)\n
We get:\n  cross_threshold_from_above_98.5\n  cross_threshold_from_above_99.0\n  cross_threshold_from_above_99.5\n  ... √ó multiple thresholds\n  √ó multiple indicator types (crossing, trending, zones, peaks)\n  √ó min/max variants\n\nTotal: ~1,982 features\n```\n\n**Benefit**: Model can learn optimal thresholds\n**Risk**: Correlated features; curse of dimensionality\n**Solution (Phase 2)**: Aggressive feature selection\n\n---\n\n## Phase 2: Feature Selection & Validation üéØ (Next)\n\n### Challenge: From 1,982 to ~100 Features\n\n**Why Reduce?**\n```\n1,982 features on 10,000 rows = 5 rows per feature\n                            \u2193\n             ‚ö†Ô∏è  EXTREME OVERFITTING RISK\n                            \u2193\n           Model memorizes training data\n           Fails on unseen test data\n```\n\n**Target**: ~100-150 features\n- High enough to capture reversal complexity\n- Low enough to avoid overfitting\n- ~70-100 rows per feature (much healthier)\n\n### Feature Selection Methods\n\n#### 1. **Correlation-Based Selection**\n
```python\n# Remove redundant features\nfor i in range(len(features)):\n    for j in range(i+1, len(features)):\n        if corr(feature[i], feature[j]) > 0.95:\n            remove_feature[j]  # Keep one, remove the other\n```\n\n**Why?** If two features are 95% correlated, they're saying the same thing\n**Impact**: Reduces 1,982 ‚Üí ~500-800 unique features\n\n---\n\n#### 2. **Mutual Information / Feature Importance**\n
```python\n# Rank features by predictive power\nfeature_importance = train_model(features, labels)\n\n# Select top N features\ntop_features = sort_by_importance(features, descending=True)[:100]\n```\n\n**Why?** Some features just don't correlate with reversals\n**Impact**: Reduces ~500 ‚Üí ~100 best features\n**Method**: Train simple model, extract feature importance\n\n---\n\n#### 3. **Recursive Feature Elimination (RFE)**\n
```python\n# Iteratively remove worst features\nwhile n_features > 100:\n    model = train_model(current_features)\n    worst_feature = get_feature_importance(model).min()\n    remove(worst_feature)\n    n_features -= 1\n```\n\n**Why?** Features interact; joint importance matters\n**Impact**: Fine-tunes final feature set\n**Advantage**: Accounts for feature interactions\n\n---\n\n### Feature Validation: Zero Lookahead Bias\n\n**Critical Audit**: For each feature, document:\n
```\nFeature Name:     cross_threshold_from_above_99.5_min\nLookback Window:  5 bars (uses prices[t-5:t])\nCurrent Bar:      t (current time)\nFuture Bars Used: NONE ‚úÖ\nCan Trade Live:   YES ‚úÖ\n```\n\n**Lookahead Red Flags**:\n- ‚ùå Feature uses prices[t+1:t+5]\n- ‚ùå Feature detects peak by looking ahead\n- ‚ùå Feature uses next bar's high/low\n- ‚ùå Feature confirms pattern after it happens\n\n**Lookahead Correct**:\n- ‚úÖ Feature only uses prices[t-N:t]\n- ‚úÖ Feature is detectable at bar t\n- ‚úÖ Feature can drive real-time trading\n- ‚úÖ Feature doesn't need future data to confirm\n\n---\n\n### Per-Stock Feature Validation\n
```python\n# Validate that features work across ALL stocks\nfor ticker_id in [1, 2, 3, 4, 5, 6]:\n    ticker_data = df[df['ticker_id'] == ticker_id]\n    
    for feature in selected_features:\n        correlation = pearson_corr(ticker_data[feature], ticker_data['class_label'])\n        if abs(correlation) < 0.01:\n            print(f\"WARNING: {feature} has no correlation for stock {ticker_id}\")\n```\n\n**Why?** A feature might work for Stock 1 but not Stock 4\n**Goal**: Select features that generalize across stocks\n\n---\n\n## Phase 3: Model Training & Evaluation ü§ñ (Final)\n\n### Step 1: Define Target Variable (Prerequisite)\n
**Before any training, we need to decide:**\n
```\nDEFINITION:\n
A reversal point at time t is identified if:\n  1. Lookback window: Compare price[t] to prices[t-5:t-1]\n  2. Lookahead window: Compare price[t] to prices[t+1:t+5]\n  3. Definition: price[t] is local minimum or local maximum\n\nMathematically:\n  is_reversal_low[t] = \n    (price[t] < min(prices[t-5:t-1])) AND\n    (price[t] < min(prices[t+1:t+5]))\n  \n  is_reversal_high[t] = \n    (price[t] > max(prices[t-5:t-1])) AND\n    (price[t] > max(prices[t+1:t+5]))\n  \n  is_reversal[t] = is_reversal_low[t] OR is_reversal_high[t]\n```\n\n**Decision**: Which definition? We have options:\n- Conservative (5 bars back/forward) - fewer reversals, higher confidence\n- Aggressive (2 bars back/forward) - more reversals, noisier labels\n- Medium (3-4 bars) - balanced\n\n---\n\n### Step 2: Handle Class Imbalance\n
**Problem**: ~85% no reversal, ~15% reversal\n\n**Solution A: Weighted Loss Functions**\n
```python\nclass_weights = {\n    0: 1.0,        # No reversal (common)\n    1: 5.67        # Reversal (rare) - weight = 85%/15%\n}\n\nmodel = XGBClassifier(\n    scale_pos_weight=class_weights[1] / class_weights[0],\n    # In XGBoost, this balances class weights\n)\n```\n\n**Intuition**: Penalize the model 5.67√ó more for missing a reversal\n\n---\n\n**Solution B: SMOTE (Synthetic Minority Oversampling)**\n
```python\nfrom imblearn.over_sampling import SMOTE\n\nsmote = SMOTE(random_state=42)\nX_resampled, y_resampled = smote.fit_resample(X, y)\n\n# Now: ~50% no reversal, ~50% reversal\n# Model trained on balanced data\n```\n\n**Tradeoff**: SMOTE creates synthetic samples (can introduce artifacts)\n\n---\n\n### Step 3: Train Classification Models\n\n#### Model 1: LightGBM (Recommended for Tabular Data)\n
```python\nimport lightgbm as lgb\n
model = lgb.LGBMClassifier(\n    n_estimators=1000,\n    max_depth=7,\n    learning_rate=0.05,\n    subsample=0.8,\n    colsample_bytree=0.8,\n    scale_pos_weight=5.67,  # Handle imbalance\n    early_stopping_rounds=50,\n    verbose=-1,\n)\n
model.fit(X_train, y_train)\n```\n\n**Why LightGBM?**\n- Fast training (minutes vs hours)\n- Handles categorical features well\n- Feature importance extraction (interpretability)\n- Low memory usage\n- Competitive performance\n\n---\n\n#### Model 2: XGBoost (Alternative)\n
```python\nimport xgboost as xgb\n
model = xgb.XGBClassifier(\n    n_estimators=500,\n    max_depth=6,\n    learning_rate=0.1,\n    scale_pos_weight=5.67,\n)\n```\n\n**Comparison**: Similar to LightGBM; slightly more robust but slower\n\n---\n\n#### Model 3: Neural Network (Advanced)\n
```python\nimport tensorflow as tf\n
model = tf.keras.Sequential([\n    tf.keras.layers.Dense(256, activation='relu', input_shape=(100,)),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(128, activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    tf.keras.layers.Dense(64, activation='relu'),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(1, activation='sigmoid'),\n])\n\nmodel.compile(\n    optimizer='adam',\n    loss=tf.keras.losses.BinaryCrossentropy(\n        class_weight={0: 1.0, 1: 5.67}  # Handle imbalance\n    ),\n    metrics=['f1_score'],\n)\n```\n\n**Pros**: Can learn complex nonlinear patterns\n**Cons**: Slower, requires more data, less interpretable\n\n---\n\n### Step 4: Proper Cross-Validation Strategy\n\n#### ‚ùå WRONG: Random Shuffle Split\n
```python\nfrom sklearn.model_selection import train_test_split\n
X_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)  # ‚ùå WRONG for time series!\n```\n\n**Problem**: Test data might contain prices from 2023, training from 2025\n**Result**: Predictions on past data; useless for future prediction\n\n---\n\n#### ‚úÖ RIGHT: Time-Based Split\n
```python\n# Sort by date first\ndf = df.sort_values('t')\n\n# Split temporally\ntrain_idx = df['t'] < '2024-10-01'  # 80% of time\ntest_idx = df['t'] >= '2024-10-01'  # 20% of time\n
X_train = df[train_idx][features]\ny_train = df[train_idx]['class_label']\n
X_test = df[test_idx][features]\ny_test = df[test_idx]['class_label']\n```\n\n**Benefit**: Training sees older data, predicts newer data (realistic)\n
---\n\n#### ‚úÖ BETTER: Time-Based K-Fold\n
```python\nfrom sklearn.model_selection import TimeSeriesSplit\n
tscv = TimeSeriesSplit(n_splits=5)\n
for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):\n    X_train = X.iloc[train_idx]\n    y_train = y.iloc[train_idx]\n    
    X_test = X.iloc[test_idx]\n    y_test = y.iloc[test_idx]\n    
    model.fit(X_train, y_train)\n    f1_scores[fold] = f1_score(y_test, model.predict(X_test))\n\nprint(f\"Average F1: {f1_scores.mean():.4f} (+/- {f1_scores.std():.4f})\")\n```\n\n**Benefit**: Multiple folds, each with temporal ordering\n**Result**: Robust estimate of real-world performance\n
---\n\n### Step 5: Evaluation Metrics (Not Just Accuracy!)\n\n```python\nfrom sklearn.metrics import f1_score, precision_score, recall_score, roc_auc_score\n\ny_pred = model.predict(X_test)\ny_pred_proba = model.predict_proba(X_test)[:, 1]\n
print(f\"F1 Score:       {f1_score(y_test, y_pred):.4f}\")  # Kaggle metric\nprint(f\"Precision:      {precision_score(y_test, y_pred):.4f}\")  # False positives\nprint(f\"Recall:         {recall_score(y_test, y_pred):.4f}\")  # False negatives\nprint(f\"ROC-AUC:        {roc_auc_score(y_test, y_pred_proba):.4f}\")  # Ranking\nprint(f\"Accuracy:       {accuracy_score(y_test, y_pred):.4f}\")  # Misleading!\n```\n\n**Key Metrics**:\n- **F1 Score**: Kaggle's evaluation metric (PRIMARY)\n- **Precision**: Avoid false reversal signals (costly in trading)\n- **Recall**: Don't miss real reversals (leave money on table)\n- **ROC-AUC**: How well model ranks reversals vs non-reversals\n- **Accuracy**: (IGNORE - misleading for imbalanced data!)\n
---\n\n### Step 6: Per-Stock Validation\n
```python\nfor ticker_id in [1, 2, 3, 4, 5, 6]:\n    ticker_mask = X_test['ticker_id'] == ticker_id\n    X_ticker = X_test[ticker_mask]\n    y_ticker = y_test[ticker_mask]\n    \n    f1_ticker = f1_score(y_ticker, model.predict(X_ticker))\n    print(f\"Stock {ticker_id} F1: {f1_ticker:.4f}\")\n```\n\n**Why?** Ensure model doesn't overfit to one stock\n**Goal**: Consistent performance across all stocks\n\n---\n\n## Summary: Our Risk Mitigations\n\n| Risk | Mitigation | Phase |\n|------|-----------|-------|\n| **Definition Ambiguity** | Clear mathematical definition + sensitivity analysis | Phase 0 |\n| **Data Leakage** | Feature audit; time-based CV only | Phase 2 |\n| **Overfitting** | Feature selection (1,982‚Üí100); regularization | Phase 2-3 |\n| **Class Imbalance** | Weighted loss + F1 metric focus | Phase 3 |\n| **Regime Changes** | Validate across all time periods | Phase 3 |\n| **Asset Heterogeneity** | Per-stock F1 scores + cross-validation | Phase 3 |\n| **Model Generalization** | Time-based CV; test on unseen future data | Phase 3 |\n
---\n\n## Expected Timeline\n
- **By Dec 20**: Phase 2 complete - 100 validated features selected\n- **By Dec 22**: Phase 3 models trained - baseline F1 ~0.55-0.60\n- **By Dec 25**: Hyperparameter tuning - target F1 ~0.65-0.70\n- **By Dec 28**: Final submission ready\n
---\n\n**Next**: Check `notebooks/newdata-us-reversal-1.ipynb` for current implementation.\n", "sha": ""}